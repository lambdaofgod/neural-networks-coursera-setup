{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Neural Networks for Machine Learning\n",
    "# Programming Assignment 2\n",
    "# Learning word representations.\n",
    "-----\n",
    "\n",
    "In this assignment, you will design a neural net language model that will\n",
    "learn to predict the next word, given previous three words.\n",
    "\n",
    "The data set consists of 4-grams (A 4-gram is a sequence of 4 adjacent words\n",
    "in a sentence). These 4-grams were extracted from a large collection of text.\n",
    "The 4-grams are chosen so that all the words involved come\n",
    "from a small vocabulary of 250 words. Note that for the purposes of this\n",
    "assignment special characters such as commas, full-stops, parentheses etc\n",
    "are also considered words. The training set consists of 372,550 4-grams. The\n",
    "validation and test sets have 46,568 4-grams each.\n",
    "\n",
    "### GETTING STARTED. ###\n",
    "Look at the file raw_sentences.txt. It contains the raw sentences from which\n",
    "these 4-grams were extracted. Take a look at the kind of sentences we are\n",
    "dealing with here. They are fairly simple ones.\n",
    "\n",
    "To load the data set, go to an octave terminal and cd to the directory where the\n",
    "downloaded data is located. Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load data.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load a struct called 'data' with 4 fields in it.\n",
    "You can see them by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = testData\n",
      "  [2,1] = trainData\n",
      "  [3,1] = validData\n",
      "  [4,1] = vocab\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "fieldnames(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'data.vocab' contains the vocabulary of 250 words. Training, validation and\n",
    "test sets are in 'data.trainData', 'data.validData' and 'data.testData'  respectively.\n",
    "To see the list of words in the vocabulary, type -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = all\n",
      "  [1,2] = set\n",
      "  [1,3] = just\n",
      "  [1,4] = show\n",
      "  [1,5] = being\n",
      "  [1,6] = money\n",
      "  [1,7] = over\n",
      "  [1,8] = both\n",
      "  [1,9] = years\n",
      "  [1,10] = four\n",
      "  [1,11] = through\n",
      "  [1,12] = during\n",
      "  [1,13] = go\n",
      "  [1,14] = still\n",
      "  [1,15] = children\n",
      "  [1,16] = before\n",
      "  [1,17] = police\n",
      "  [1,18] = office\n",
      "  [1,19] = million\n",
      "  [1,20] = also\n",
      "  [1,21] = less\n",
      "  [1,22] = had\n",
      "  [1,23] = ,\n",
      "  [1,24] = including\n",
      "  [1,25] = should\n",
      "  [1,26] = to\n",
      "  [1,27] = only\n",
      "  [1,28] = going\n",
      "  [1,29] = under\n",
      "  [1,30] = has\n",
      "  [1,31] = might\n",
      "  [1,32] = do\n",
      "  [1,33] = them\n",
      "  [1,34] = good\n",
      "  [1,35] = around\n",
      "  [1,36] = get\n",
      "  [1,37] = very\n",
      "  [1,38] = big\n",
      "  [1,39] = dr.\n",
      "  [1,40] = game\n",
      "  [1,41] = every\n",
      "  [1,42] = know\n",
      "  [1,43] = they\n",
      "  [1,44] = not\n",
      "  [1,45] = world\n",
      "  [1,46] = now\n",
      "  [1,47] = him\n",
      "  [1,48] = school\n",
      "  [1,49] = several\n",
      "  [1,50] = like\n",
      "  [1,51] = did\n",
      "  [1,52] = university\n",
      "  [1,53] = companies\n",
      "  [1,54] = these\n",
      "  [1,55] = she\n",
      "  [1,56] = team\n",
      "  [1,57] = found\n",
      "  [1,58] = where\n",
      "  [1,59] = right\n",
      "  [1,60] = says\n",
      "  [1,61] = people\n",
      "  [1,62] = house\n",
      "  [1,63] = national\n",
      "  [1,64] = some\n",
      "  [1,65] = back\n",
      "  [1,66] = see\n",
      "  [1,67] = street\n",
      "  [1,68] = are\n",
      "  [1,69] = year\n",
      "  [1,70] = home\n",
      "  [1,71] = best\n",
      "  [1,72] = out\n",
      "  [1,73] = even\n",
      "  [1,74] = what\n",
      "  [1,75] = said\n",
      "  [1,76] = for\n",
      "  [1,77] = federal\n",
      "  [1,78] = since\n",
      "  [1,79] = its\n",
      "  [1,80] = may\n",
      "  [1,81] = state\n",
      "  [1,82] = does\n",
      "  [1,83] = john\n",
      "  [1,84] = between\n",
      "  [1,85] = new\n",
      "  [1,86] = ;\n",
      "  [1,87] = three\n",
      "  [1,88] = public\n",
      "  [1,89] = ?\n",
      "  [1,90] = be\n",
      "  [1,91] = we\n",
      "  [1,92] = after\n",
      "  [1,93] = business\n",
      "  [1,94] = never\n",
      "  [1,95] = use\n",
      "  [1,96] = here\n",
      "  [1,97] = york\n",
      "  [1,98] = members\n",
      "  [1,99] = percent\n",
      "  [1,100] = put\n",
      "  [1,101] = group\n",
      "  [1,102] = come\n",
      "  [1,103] = by\n",
      "  [1,104] = $\n",
      "  [1,105] = on\n",
      "  [1,106] = about\n",
      "  [1,107] = last\n",
      "  [1,108] = her\n",
      "  [1,109] = of\n",
      "  [1,110] = could\n",
      "  [1,111] = days\n",
      "  [1,112] = against\n",
      "  [1,113] = times\n",
      "  [1,114] = women\n",
      "  [1,115] = place\n",
      "  [1,116] = think\n",
      "  [1,117] = first\n",
      "  [1,118] = among\n",
      "  [1,119] = own\n",
      "  [1,120] = family\n",
      "  [1,121] = into\n",
      "  [1,122] = each\n",
      "  [1,123] = one\n",
      "  [1,124] = down\n",
      "  [1,125] = because\n",
      "  [1,126] = long\n",
      "  [1,127] = another\n",
      "  [1,128] = such\n",
      "  [1,129] = old\n",
      "  [1,130] = next\n",
      "  [1,131] = your\n",
      "  [1,132] = market\n",
      "  [1,133] = second\n",
      "  [1,134] = city\n",
      "  [1,135] = little\n",
      "  [1,136] = from\n",
      "  [1,137] = would\n",
      "  [1,138] = few\n",
      "  [1,139] = west\n",
      "  [1,140] = there\n",
      "  [1,141] = political\n",
      "  [1,142] = two\n",
      "  [1,143] = been\n",
      "  [1,144] = .\n",
      "  [1,145] = their\n",
      "  [1,146] = much\n",
      "  [1,147] = music\n",
      "  [1,148] = too\n",
      "  [1,149] = way\n",
      "  [1,150] = white\n",
      "  [1,151] = :\n",
      "  [1,152] = was\n",
      "  [1,153] = war\n",
      "  [1,154] = today\n",
      "  [1,155] = more\n",
      "  [1,156] = ago\n",
      "  [1,157] = life\n",
      "  [1,158] = that\n",
      "  [1,159] = season\n",
      "  [1,160] = company\n",
      "  [1,161] = -\n",
      "  [1,162] = but\n",
      "  [1,163] = part\n",
      "  [1,164] = court\n",
      "  [1,165] = former\n",
      "  [1,166] = general\n",
      "  [1,167] = with\n",
      "  [1,168] = than\n",
      "  [1,169] = those\n",
      "  [1,170] = he\n",
      "  [1,171] = me\n",
      "  [1,172] = high\n",
      "  [1,173] = made\n",
      "  [1,174] = this\n",
      "  [1,175] = work\n",
      "  [1,176] = up\n",
      "  [1,177] = us\n",
      "  [1,178] = until\n",
      "  [1,179] = will\n",
      "  [1,180] = ms.\n",
      "  [1,181] = while\n",
      "  [1,182] = officials\n",
      "  [1,183] = can\n",
      "  [1,184] = were\n",
      "  [1,185] = country\n",
      "  [1,186] = my\n",
      "  [1,187] = called\n",
      "  [1,188] = and\n",
      "  [1,189] = program\n",
      "  [1,190] = have\n",
      "  [1,191] = then\n",
      "  [1,192] = is\n",
      "  [1,193] = it\n",
      "  [1,194] = an\n",
      "  [1,195] = states\n",
      "  [1,196] = case\n",
      "  [1,197] = say\n",
      "  [1,198] = his\n",
      "  [1,199] = at\n",
      "  [1,200] = want\n",
      "  [1,201] = in\n",
      "  [1,202] = any\n",
      "  [1,203] = as\n",
      "  [1,204] = if\n",
      "  [1,205] = united\n",
      "  [1,206] = end\n",
      "  [1,207] = no\n",
      "  [1,208] = )\n",
      "  [1,209] = make\n",
      "  [1,210] = government\n",
      "  [1,211] = when\n",
      "  [1,212] = american\n",
      "  [1,213] = same\n",
      "  [1,214] = how\n",
      "  [1,215] = mr.\n",
      "  [1,216] = other\n",
      "  [1,217] = take\n",
      "  [1,218] = which\n",
      "  [1,219] = department\n",
      "  [1,220] = --\n",
      "  [1,221] = you\n",
      "  [1,222] = many\n",
      "  [1,223] = nt\n",
      "  [1,224] = day\n",
      "  [1,225] = week\n",
      "  [1,226] = play\n",
      "  [1,227] = used\n",
      "  [1,228] = 's\n",
      "  [1,229] = though\n",
      "  [1,230] = our\n",
      "  [1,231] = who\n",
      "  [1,232] = yesterday\n",
      "  [1,233] = director\n",
      "  [1,234] = most\n",
      "  [1,235] = president\n",
      "  [1,236] = law\n",
      "  [1,237] = man\n",
      "  [1,238] = a\n",
      "  [1,239] = night\n",
      "  [1,240] = off\n",
      "  [1,241] = center\n",
      "  [1,242] = i\n",
      "  [1,243] = well\n",
      "  [1,244] = or\n",
      "  [1,245] = without\n",
      "  [1,246] = so\n",
      "  [1,247] = time\n",
      "  [1,248] = five\n",
      "  [1,249] = the\n",
      "  [1,250] = left\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'data.trainData' is a matrix of 372550 X 4. This means there are 372550\n",
    "training cases and 4 words per training case. Each entry is an integer that is\n",
    "the index of a word in the vocabulary. So each row represents a sequence of 4\n",
    "words. 'data.validData' and 'data.testData' are also similar. They contain\n",
    "46,568 4-grams each. All three need to be separated into inputs and targets\n",
    "and the training set needs to be split into mini-batches. The file load_data.m\n",
    "provides code for doing that. To run it type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[train_x, train_t, valid_x, valid_t, test_x, test_t, vocab] = load_data(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load the data, separate it into inputs and target, and make\n",
    "mini-batches of size 100 for the training set.\n",
    "\n",
    "train.m implements the function that trains a neural net language model.\n",
    "To run the training, execute the following -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch 100 Train CE 5.521\n",
      "Batch 200 Train CE 5.521\n",
      "Batch 300 Train CE 5.521\n",
      "Batch 400 Train CE 5.521\n",
      "Batch 500 Train CE 5.521\n",
      "Batch 600 Train CE 5.521\n",
      "Batch 700 Train CE 5.521\n",
      "Batch 800 Train CE 5.521\n",
      "Batch 900 Train CE 5.521\n",
      "Batch 1000 Train CE 5.521\n",
      "Running validation ... Validation CE 5.521\n",
      "Batch 1100 Train CE 5.521\n",
      "Batch 1200 Train CE 5.521\n",
      "Batch 1300 Train CE 5.521\n",
      "Batch 1400 Train CE 5.521\n",
      "Batch 1500 Train CE 5.521\n",
      "Batch 1590 Train CE 5.521\n"
     ]
    }
   ],
   "source": [
    "model = train(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will train the model for one epoch (one pass through the training set).\n",
    "Currently, the training is not implemented and the cross entropy will not\n",
    "decrease. You have to fill in parts of the code in fprop.m and train.m.\n",
    "Once the code is correctly filled-in, you will see that the cross entropy\n",
    "starts decreasing. At this point, try changing the hyperparameters (number\n",
    "of epochs, number of hidden units, learning rates, momentum, etc) and see\n",
    "what effect that has on the training and validation cross entropy. The\n",
    "questions in the assignment will ask you try out specific values of these.\n",
    "\n",
    "The training method will output a 'model' (a struct containing weights, biases\n",
    "and a list of words). Now it's time to play around with the learned model\n",
    "and answer the questions in the assignment.\n",
    "\n",
    "### DESCRIPTION OF THE NETWORK. ###\n",
    "The network consists of an input layer, embedding layer, hidden layer and output\n",
    "layer. The input layer consists of three word indices. The same\n",
    "'word_embedding_weights' are used to map each index to a distributed feature\n",
    "representation. These mapped features constitute the embedding layer. This layer\n",
    "is connected to the hidden layer, which in turn is connected to the output\n",
    "layer. The output layer is a softmax over the 250 words.\n",
    "\n",
    "### THINGS YOU SEE WHEN THE MODEL IS TRAINING. ###\n",
    "As the model trains it prints out some numbers that tell you how well the\n",
    "training is going.\n",
    "(1) The model shows the average per-case cross entropy (CE) obtained\n",
    "on the training set. The average CE is computed every 100 mini-batches. The\n",
    "average CE over the entire training set is reported at the end of every epoch.\n",
    "\n",
    "(2) After every 1000 mini-batches of training, the model is run on the\n",
    "validation set. Recall, that the validation set consists of data that is not\n",
    "used for training. It is used to see how well the model does on unseen data. The\n",
    "cross entropy on validation set is reported.\n",
    "\n",
    "(3) At the end of training, the model is run both on the validation set and on\n",
    "the test set and the cross entropy on both is reported.\n",
    "\n",
    "You are welcome to change these numbers (100 and 1000) to see the CE's more\n",
    "frequently if you want to.\n",
    "\n",
    "\n",
    "### SOME USEFUL FUNCTIONS. ###\n",
    "These functions are meant to be used for analyzing the model after the training\n",
    "is done.\n",
    "  display_nearest_words.m : This method will display the words closest to a\n",
    "    given word in the word representation space.\n",
    "  word_distance.m : This method will compute the distance between two given\n",
    "    words.\n",
    "  predict_next_word.m : This method will produce some predictions for the next\n",
    "    word given 3 previous words.\n",
    "Take a look at the documentation inside these functions to see how to use them.\n",
    "\n",
    "\n",
    "### THINGS TO TRY. ###\n",
    "Choose some words from the vocabulary and make a list. Find the words that\n",
    "the model thinks are close to words in this list (for example, find the words\n",
    "closest to 'companies', 'president', 'day', 'could', etc). Do the outputs make\n",
    "sense ?\n",
    "\n",
    "Pick three words from the vocabulary that go well together (for example,\n",
    "'government of united', 'city of new', 'life in the', 'he is the' etc). Use\n",
    "the model to predict the next word. Does the model give sensible predictions?\n",
    "\n",
    "Which words would you expect to be closer together than others ? For example,\n",
    "'he' should be closer to 'she' than to 'federal', or 'companies' should be\n",
    "closer to 'business' than 'political'. Find the distances using the model.\n",
    "Do the distances that the model predicts make sense ?\n",
    "\n",
    "You are welcome to try other things with this model and post any interesting\n",
    "observations on the forums!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
